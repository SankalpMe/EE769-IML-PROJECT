{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "22f72ef0-0d69-4afb-93f3-85de41772f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from dask import delayed\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron, RidgeClassifier\n",
    "\n",
    "from sympy import Symbol\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2739c00-d573-42a9-a5a0-5b3b26b6e4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FACE_SIZE = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8204a0f-d6f0-43ed-824d-b50c67f94bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_intg_image(img):\n",
    "    \"\"\"\n",
    "    Computes matrix for quick computation of integrals.\n",
    "    \"\"\"\n",
    "    # Create a matrix of zeros with the same dimensions as the input image\n",
    "    intg_img = np.zeros((img.shape[0]+1, img.shape[1]+1) , dtype=np.int64)\n",
    "    \n",
    "    # Iterate over each pixel in the input image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the sum of all pixels above and to the left of the current pixel\n",
    "            intg_img[i+1, j+1] = intg_img[i, j+1] + intg_img[i+1, j] - intg_img[i, j] + img[i, j]\n",
    "\n",
    "    # Return the computed integral image\n",
    "    return intg_img\n",
    "\n",
    "def get_rect(intg_img, si, sj, ei, ej):\n",
    "    \"\"\"\n",
    "    Computes integral in rect by top left corner to bottom right\n",
    "    \"\"\"\n",
    "    # Calculate the sum of all pixels within the specified rectangular region\n",
    "    result = intg_img[ei+1, ej+1] - intg_img[si, ej+1] - intg_img[ei+1, sj] + intg_img[si, sj]\n",
    "    \n",
    "    # Return the computed sum of pixels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85e2a20a-9a53-4987-b710-1540d149eec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_features_from_filter(h, w, filt_type):\n",
    "    gen_features = []\n",
    "    for i in range(FACE_SIZE-h+1):\n",
    "        for j in range(FACE_SIZE-w+1):\n",
    "            gen_features.append((h,w, filt_type, i, j))\n",
    "    return gen_features\n",
    "\n",
    "def generate_haar_filters():\n",
    "    # (r, c, is_vert, i, j)\n",
    "    haar_features= []\n",
    "    for i in range(1, FACE_SIZE+1):\n",
    "        for j in range(1, FACE_SIZE+1):\n",
    "            if i % 2 == 0: #vert-seg\n",
    "                filter_type = 0\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "            if j % 2 == 0: #hori-seg\n",
    "                filter_type = 1\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "            if j % 3 == 0: #hori-seg\n",
    "                filter_type = 2\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "            if i % 3 == 0: #vert-seg\n",
    "                filter_type = 3\n",
    "                haar_features += generate_features_from_filter(i, j, filter_type)\n",
    "\n",
    "    return haar_features\n",
    "\n",
    "def compute_haar_feature(intg_img, haar_feature):\n",
    "    h, w, filt_type, i, j = haar_feature\n",
    "    result = 0\n",
    "    if filt_type == 0:\n",
    "        result = 2 * ( intg_img[i+h, j+w] - 2*intg_img[i+h//2, j+w] - intg_img[i+h, j] + 2*intg_img[i+h//2, j] + intg_img[i, j+w] - intg_img[i, j]) / (h*w)\n",
    "    elif filt_type == 1:\n",
    "        result = 2*(2*intg_img[h + i, j + w//2] - intg_img[h + i, j + w] - intg_img[h + i, j] - 2*intg_img[i, j + w//2] + intg_img[i, j + w] + intg_img[i, j]) / (h*w)\n",
    "    elif filt_type == 2:\n",
    "        result = (3*intg_img[h + i, j + 2*w//3] - 3*intg_img[h + i, j + w//3] - intg_img[h + i, j + w] + intg_img[h + i, j] - 3*intg_img[i, j + 2*w//3] + 3*intg_img[i, j + w//3] + intg_img[i, j + w] - intg_img[i, j]) / (h*w) * 1.5\n",
    "    elif filt_type == 3:\n",
    "        result = (-intg_img[h + i, j + w] + intg_img[h + i, j] + 3*intg_img[h//3 + i, j + w] - 3*intg_img[h//3 + i, j] - intg_img[i + 2*h//3, j + w] + intg_img[i + 2*h//3, j] - intg_img[i, j + w] + intg_img[i, j])/(h*w)*1.5\n",
    "    return result\n",
    "\n",
    "def compute_haar_coef(intg_img, haar_filter_set):\n",
    "    return np.hstack([compute_haar_feature(intg_img, filt) for filt in haar_filter_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "16e8521c-8637-4b52-8747-419c48a9357d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    imgs = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".pgm\" in file:\n",
    "            imgs.append(cv2.imread(folder+\"/\"+file,-1))\n",
    "    return imgs\n",
    "\n",
    "def load_data(folder):\n",
    "    train_x_true = load_folder(folder+\"/face\")[:1000]\n",
    "    train_x_false = load_folder(folder+\"/non-face\")[:3000]\n",
    "\n",
    "    train_y_true = [1] * len(train_x_true)\n",
    "    train_y_false = [0] * len(train_x_false)\n",
    "\n",
    "    train_x = train_x_true + train_x_false\n",
    "    train_y = train_y_true + train_y_false\n",
    "    train_x = [compute_intg_image(img) for img in train_x]\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b82a5995-2a0d-4484-9438-c3e43d2b4fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, train_y = load_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ba6aa9ed-e5da-49b6-98d1-378d829462b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Adaboost(train_x, train_y, d=1, T=100):\n",
    "    face_count = 0\n",
    "    non_face_count = 0\n",
    "    for i, label in enumerate(train_y):\n",
    "        if label:\n",
    "            face_count += 1\n",
    "        else:\n",
    "            non_face_count += 1\n",
    "    print(face_count, non_face_count)\n",
    "    w = np.array([1/face_count if train_y[i] else 1/non_face_count for i in range(len(train_y))])\n",
    "\n",
    "    classifiers = []\n",
    "    feature_sel = []\n",
    "    betas = []\n",
    "    model_threshold = 0\n",
    "    def select_features(x_data, x_sel):\n",
    "        return [[x[f] for f in x_sel] for x in x_data]\n",
    "    predictions = np.zeros(train_y.shape)\n",
    "    pbar = tqdm.tqdm(range(T))\n",
    "    for t in pbar:\n",
    "        w = w / np.sum(w)\n",
    "        while True: \n",
    "            model = RidgeClassifier()\n",
    "            m_sel = np.random.permutation(len(train_x[0]))[:d]\n",
    "            m_train_x = select_features(train_x, m_sel)\n",
    "            model.fit(m_train_x, train_y, sample_weight=w)\n",
    "            e = np.abs(train_y - model.predict(m_train_x))\n",
    "            \n",
    "            beta = np.sum(w * e)\n",
    "            if beta < 0.5:\n",
    "                \n",
    "                feature_sel.append(m_sel)\n",
    "                w = w * np.power(beta, 1-e)\n",
    "                classifiers.append(model)\n",
    "                betas.append(beta+1e-6)\n",
    "                break\n",
    "        alpha = -np.log(betas)\n",
    "        predictions = predictions + alpha[-1]*np.array(classifiers[-1].predict(select_features(train_x, feature_sel[-1])))\n",
    "        model_threshold = np.min(predictions[train_y==1])\n",
    "        miss_classification = np.sum((predictions >= model_threshold) != train_y)\n",
    "        pbar.set_description(f'Error: {miss_classification}')\n",
    "        if miss_classification == 0:\n",
    "            break  \n",
    "        \n",
    "    \n",
    "    def model(x):\n",
    "        preds = np.sum( np.array([c.predict(select_features(x, f_sel)) for c, f_sel in zip(classifiers, feature_sel)]) * alpha.reshape(-1,1), axis=0)\n",
    "        return preds >= model_threshold\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7ebb4780-a48f-4d6b-b56e-c9452c3babfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_classifier(train_x, train_y):\n",
    "    final_cascade = []\n",
    "    x = train_x\n",
    "    y = np.array(train_y)\n",
    "    d_size = 1\n",
    "    while True:\n",
    "        model=Adaboost(x,y,  200,20)\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        pos_sample = np.argwhere(y_pred==True).flatten()\n",
    "        new_x = [x[i] for i in pos_sample]\n",
    "        new_y = [y[i] for i in pos_sample]\n",
    "        d_size += 1\n",
    "        final_cascade.append(model)\n",
    "        if( (y_pred==y).all() ):\n",
    "            break\n",
    "\n",
    "        x = new_x\n",
    "        y = np.array(new_y)\n",
    "    return final_cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e492c69f-18be-4ca3-8c01-895b9ffd4406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "haar_filters = generate_haar_filters()\n",
    "np.random.shuffle(haar_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eb5c0bc6-c460-4252-adc9-7e52a6f258dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: 1 - 100\n",
      "Train start\n",
      "1000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: 816: 100%|█████████████████████████████| 100/100 [00:13<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Stage: 2 - 300\n",
      "Train start\n",
      "1000 816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: 46: 100%|██████████████████████████████| 100/100 [00:19<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Stage: 3 - 700\n",
      "Train start\n",
      "1000 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: 0:   3%|▉                                | 3/100 [00:00<00:31,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "final_cascade = []\n",
    "final_filters = []\n",
    "stage_filters = []\n",
    "x = train_x\n",
    "y = np.array(train_y)\n",
    "d_size = 1\n",
    "filt_size = 100\n",
    "while True:\n",
    "    stage_filters += haar_filters[:filt_size]\n",
    "    haar_filters = haar_filters[filt_size+1:]\n",
    "    filt_size *= 2\n",
    "    filt_size = min(filt_size, len(haar_filters))\n",
    "    print(f\"Stage: {len(final_cascade)+1} - {len(stage_filters)}\")\n",
    "    f_x = [compute_haar_coef(img, stage_filters) for img in x]\n",
    "    print(\"Train start\")\n",
    "    model=Adaboost(f_x, y, len(stage_filters)//2, 100)\n",
    "    print(\"Done\")\n",
    "    y_pred = model(f_x)\n",
    "\n",
    "    pos_sample = np.argwhere(y_pred==True).flatten()\n",
    "    new_x = [x[i] for i in pos_sample]\n",
    "    new_y = [y[i] for i in pos_sample]\n",
    "    d_size += 1\n",
    "    final_cascade.append(model)\n",
    "    final_filters.append(len(stage_filters))\n",
    "    if( (y_pred==y).all() ):\n",
    "        break\n",
    "    x = new_x\n",
    "    y = np.array(new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a58428c2-baa4-4c30-9520-97b1cdf0829d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " def check_img(img):\n",
    "    intg_img = compute_intg_image(img)\n",
    "    filt_size = 100\n",
    "    t_filt = 100\n",
    "    for i in range(len(final_cascade)):\n",
    "        s_f = stage_filters[:t_filt]\n",
    "        filt_size *= 2\n",
    "        t_filt += filt_size\n",
    "        filt_size = min(filt_size, len(haar_filters))\n",
    "        f_x = compute_haar_coef(intg_img, s_f)\n",
    "        if not(final_cascade[i]([f_x])):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b725a22d-2e1e-4d67-8f7d-57d739f39fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_img(load_folder('data')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dcbdc997-c8c7-4a49-b604-59fe6d9a1b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mk_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, k_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mk_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, k_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mcheck_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m ):\n\u001b[1;32m     15\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mrectangle(cimg, (j,i), (j\u001b[38;5;241m+\u001b[39mk_size, i\u001b[38;5;241m+\u001b[39mk_size), \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     16\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m'\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mresize(img[i:i\u001b[38;5;241m+\u001b[39mk_size, j:j\u001b[38;5;241m+\u001b[39mk_size], (\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m)) )\n",
      "Cell \u001b[0;32mIn[160], line 11\u001b[0m, in \u001b[0;36mcheck_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      9\u001b[0m     filt_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(filt_size, \u001b[38;5;28mlen\u001b[39m(haar_filters))\n\u001b[1;32m     10\u001b[0m     f_x \u001b[38;5;241m=\u001b[39m compute_haar_coef(intg_img, s_f)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(\u001b[43mfinal_cascade\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf_x\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[163], line 47\u001b[0m, in \u001b[0;36mAdaboost.<locals>.model\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(x):\n\u001b[0;32m---> 47\u001b[0m     preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum( np\u001b[38;5;241m.\u001b[39marray([c\u001b[38;5;241m.\u001b[39mpredict(select_features(x, f_sel)) \u001b[38;5;28;01mfor\u001b[39;00m c, f_sel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classifiers, feature_sel)]) \u001b[38;5;241m*\u001b[39m alpha\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m model_threshold\n",
      "Cell \u001b[0;32mIn[163], line 47\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel\u001b[39m(x):\n\u001b[0;32m---> 47\u001b[0m     preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum( np\u001b[38;5;241m.\u001b[39marray([\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_sel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c, f_sel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classifiers, feature_sel)]) \u001b[38;5;241m*\u001b[39m alpha\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m model_threshold\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1212\u001b[0m, in \u001b[0;36m_RidgeClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer\u001b[38;5;241m.\u001b[39minverse_transform(scores)\n\u001b[0;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:402\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    400\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    401\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(scores, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:63\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_NumPyApiWrapper\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Array API compat wrapper for any numpy version\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    NumPy < 1.22 does not expose the numpy.array_api namespace. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    See the `get_namespace()` public function for more details.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(numpy, name)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, dtype, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;66;03m# astype is not defined in the top level NumPy namespace\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    img = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), (200,200))\n",
    "    cimg = img.copy()\n",
    "    k_size = 80\n",
    "    for i in range(0,img.shape[0]-k_size+1, k_size//2):\n",
    "        for j in range(0,img.shape[1]-k_size+1, k_size//2):\n",
    "            if(check_img(cv2.resize(img[i:i+k_size, j:j+k_size], (19,19))) ):\n",
    "                cv2.rectangle(cimg, (j,i), (j+k_size, i+k_size), 255, 2)\n",
    "                cv2.imshow('face',cv2.resize(img[i:i+k_size, j:j+k_size], (50,50)) )\n",
    "                cv2.waitKey(1)\n",
    "            cv2.imshow('frame', cimg)\n",
    "            cv2.waitKey(5)\n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "03f441d1-1525-4d87-be59-d4e560e95bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6a089-fd2b-4222-8b15-628699e6eca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
