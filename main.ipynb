{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from dask import delayed\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Integral Image\n",
    "\n",
    "Computes rectangle integrals of an image for fast computation of Harr Filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intg_image(img):\n",
    "    \"\"\"\n",
    "    Computes matrix for quick computation of integrals.\n",
    "    \"\"\"\n",
    "    # Create a matrix of zeros with the same dimensions as the input image\n",
    "    intg_img = np.zeros(img.shape, dtype=np.int64)\n",
    "    \n",
    "    # Iterate over each pixel in the input image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the sum of all pixels above and to the left of the current pixel\n",
    "            if i > 0:\n",
    "                intg_img[i, j] += intg_img[i-1, j]\n",
    "            if j > 0:\n",
    "                intg_img[i, j] += intg_img[i, j-1]\n",
    "            if i > 0 and j > 0:\n",
    "                intg_img[i, j] -= intg_img[i-1, j-1]\n",
    "            \n",
    "            # Add the value of the current pixel to the integral image\n",
    "            intg_img[i, j] += img[i, j]\n",
    "    \n",
    "    # Return the computed integral image\n",
    "    return intg_img\n",
    "\n",
    "def get_rect(intg_img, si, sj, ei, ej):\n",
    "    # Calculate the sum of all pixels within the specified rectangular region\n",
    "    result = intg_img[ei, ej]\n",
    "    if si > 0:\n",
    "        result -= intg_img[si-1, ej]\n",
    "    if sj > 0:\n",
    "        result -= intg_img[ei, sj-1]\n",
    "    if si > 0 and sj > 0:\n",
    "        result += intg_img[si-1, sj-1]\n",
    "    \n",
    "    # Return the computed sum of pixels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    imgs = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".pgm\" in file:\n",
    "            imgs.append(cv2.imread(folder+\"/\"+file,-1))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haar_features(intg_img, haar_filters, feature_size):\n",
    "    haar_features = []\n",
    "    \n",
    "    for filter in haar_filters:\n",
    "        filter_feature = []\n",
    "        for i in range(intg_img.shape[0]-filter[0]+1):\n",
    "            for j in range(intg_img.shape[1]-filter[1]+1):\n",
    "                if filter[2] == 2:\n",
    "                    result = ( -get_rect(intg_img, i, j, i+filter[0]-1, j+filter[1]//3-1) \n",
    "                              + get_rect(intg_img, i, j+filter[1]//3, i+filter[0]-1, j+2*filter[1]//3-1)*2 \n",
    "                    - get_rect(intg_img, i, j+2*filter[1]//3, i+filter[0]-1, j+filter[1]-1) )*3/(2*(filter[0])*filter[1])\n",
    "                if filter[2] == 1:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]-1, j+filter[1]//2-1) \n",
    "                    - get_rect(intg_img, i, j+filter[1]//2, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])*2\n",
    "                elif filter[2] == 0:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]//2-1, j +filter[1]-1) \n",
    "                    - get_rect(intg_img, i+filter[0]//2, j, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])*2\n",
    "                filter_feature.append(result)\n",
    "        haar_features.append(filter_feature)\n",
    "\n",
    "    return haar_features\n",
    "def generate_haar_filters(detector_size=19):\n",
    "    haar_feature_size = 0\n",
    "    # (r, c, is_vert)\n",
    "    haar_filters= []\n",
    "    for i in range(1, detector_size+1):\n",
    "        for j in range(1, detector_size+1):\n",
    "            if i % 2 == 0:\n",
    "                haar_filters.append((i,j, 0))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "            if j % 2 == 0:\n",
    "                haar_filters.append((i,j, 1))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "            if j % 3 == 0:\n",
    "                haar_filters.append((i,j, 2))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "    return haar_feature_size, haar_filters\n",
    "\n",
    "def get_haar_feature_extractor(detector_size):\n",
    "    haar_feature_size, haar_filters = generate_haar_filters(detector_size)\n",
    "    @delayed\n",
    "    def get_haar(intg_img):\n",
    "        return compute_haar_features(intg_img, haar_filters, haar_feature_size)\n",
    "    return get_haar\n",
    "\n",
    "haar_feature_extractor = get_haar_feature_extractor(19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1300.96it/s]\n"
     ]
    }
   ],
   "source": [
    "rand_ind = np.random.permutation(2000)[:1000]\n",
    "train_x_true = load_folder(\"train/face\")\n",
    "train_x_true = [train_x_true[i] for i in rand_ind]\n",
    "train_x_false = load_folder(\"train/non-face\")\n",
    "train_x_false = [train_x_false[i] for i in rand_ind]\n",
    "train_y_true = [1] * len(train_x_true)\n",
    "train_y_false = [0] * len(train_x_false)\n",
    "\n",
    "train_x = train_x_true + train_x_false\n",
    "train_y = train_y_true + train_y_false\n",
    "\n",
    "train_x = delayed(haar_feature_extractor(compute_intg_image(img)) for img in tqdm.tqdm(train_x) )\n",
    "\n",
    "train_x = train_x.compute(scheduler='single-threaded')\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adaboost(train_x, train_y, d=1, T=100):\n",
    "    face_count = 0\n",
    "    non_face_count = 0\n",
    "    for i, label in enumerate(train_y):\n",
    "        if label:\n",
    "            face_count += 1\n",
    "        else:\n",
    "            non_face_count += 1\n",
    "    print(face_count, non_face_count)\n",
    "    w = np.array([1/face_count if train_y[i] else 1/non_face_count for i in range(len(train_y))])\n",
    "\n",
    "    classifiers = []\n",
    "    feature_sel = []\n",
    "    betas = []\n",
    "    model_threshold = 0\n",
    "    def select_features(x_data, x_sel):\n",
    "        return [np.hstack([x[f] for f in x_sel]) for x in x_data]\n",
    "    predictions = np.zeros(train_y.shape)\n",
    "    pbar = tqdm.tqdm(range(T))\n",
    "    for t in pbar:\n",
    "        w = w / np.sum(w)\n",
    "        while True: \n",
    "            model = RidgeClassifier()\n",
    "            m_sel = np.random.permutation(len(train_x[0]))[:d]\n",
    "            m_train_x = select_features(train_x, m_sel)\n",
    "            model.fit(m_train_x, train_y, sample_weight=w)\n",
    "            e = np.abs(train_y - model.predict(m_train_x))\n",
    "            \n",
    "            beta = np.sum(w * e)\n",
    "            if beta < 0.5:\n",
    "                \n",
    "                feature_sel.append(m_sel)\n",
    "                w = w * np.power(beta, 1-e)\n",
    "                classifiers.append(model)\n",
    "                betas.append(beta+1e-6)\n",
    "                break\n",
    "        alpha = -np.log(betas)\n",
    "        predictions = predictions + alpha[-1]*np.array(classifiers[-1].predict(select_features(train_x, feature_sel[-1])))\n",
    "        model_threshold = np.min(predictions[train_y==1])\n",
    "        miss_classification = np.sum((predictions >= model_threshold) != train_y)\n",
    "        pbar.set_description(f'Error: {miss_classification}')\n",
    "        if miss_classification == 0:\n",
    "            break  \n",
    "        \n",
    "    \n",
    "    def model(x):\n",
    "        preds = np.sum( np.array([c.predict(select_features(x, f_sel)) for c, f_sel in zip(classifiers, feature_sel)]) * alpha.reshape(-1,1), axis=0)\n",
    "        return preds >= model_threshold\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(train_x, train_y):\n",
    "    final_cascade = []\n",
    "    x = train_x\n",
    "    y = np.array(train_y)\n",
    "    d_size = 1\n",
    "    while True:\n",
    "        model=Adaboost(x,y,  200,20)\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        pos_sample = np.argwhere(y_pred==True).flatten()\n",
    "        new_x = [x[i] for i in pos_sample]\n",
    "        new_y = [y[i] for i in pos_sample]\n",
    "        d_size += 1\n",
    "        final_cascade.append(model)\n",
    "        if( (y_pred==y).all() ):\n",
    "            break\n",
    "\n",
    "        x = new_x\n",
    "        y = np.array(new_y)\n",
    "    return final_cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: 0:   0%|          | 0/20 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "cascade = train_classifier(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function __main__.Adaboost.<locals>.model(x)>]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_true = load_folder(\"train/face\")[600:620]\n",
    "test_x_false = load_folder(\"train/non-face\")[600:620]\n",
    "test_y_true = [1] * len(test_x_true)\n",
    "test_y_false = [0] * len(test_x_false)\n",
    "\n",
    "test_x = test_x_true + test_x_false\n",
    "test_y = test_y_true + test_y_false\n",
    "\n",
    "test_x = delayed(haar_feature_extractor(compute_intg_image(img)) for img in test_x)\n",
    "test_x = test_x.compute(scheduler='single-threaded')\n",
    "test_y = np.array(test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_img(cascade, img):\n",
    "    for model in cascade:\n",
    "        if not model([img])[0]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([raw_img(cascade, img) for img in test_x])) == test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_img(cascade, img):\n",
    "    intg_img = compute_intg_image(img)\n",
    "    \n",
    "    haar_features = [haar_feature_extractor(intg_img).compute()]\n",
    "    \n",
    "    for model in cascade:\n",
    "        if not model(haar_features)[0]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_img(cascade,load_folder(\"data\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_folder(\"data\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m                 cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m             cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m, cimg)\n\u001b[0;32m---> 19\u001b[0m             cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m \u001b[39m# After the loop release the cap object\u001b[39;00m\n\u001b[1;32m     21\u001b[0m vid\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    img = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), (200,200))\n",
    "    cimg = img.copy()\n",
    "    k_size = 80\n",
    "    for i in range(0,img.shape[0]-k_size+1, k_size//2):\n",
    "        for j in range(0,img.shape[1]-k_size+1, k_size//2):\n",
    "            if(check_img(cascade, cv2.resize(img[i:i+k_size, j:j+k_size], (19,19))) ):\n",
    "                cv2.rectangle(cimg, (j,i), (j+k_size, i+k_size), 255, 2)\n",
    "                cv2.imshow('face',cv2.resize(img[i:i+k_size, j:j+k_size], (50,50)) )\n",
    "                cv2.waitKey(1)\n",
    "            cv2.imshow('frame', cimg)\n",
    "            cv2.waitKey(5)\n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rect(si, sj, ei, ej):\n",
    "    return Symbol(f\"intg_img[{str(ei+1)}, {str(ej+1)}]\") - Symbol(f\"intg_img[{str(si)}, {str(ej+1)}]\")  - Symbol(f\"intg_img[{str(ei+1)}, {str(sj)}]\") + Symbol(f\"intg_img[{str(si)}, {str(sj)}]\")\n",
    "i = Symbol('i')\n",
    "j = Symbol('j')\n",
    "h = Symbol('h')\n",
    "w = Symbol('w')\n",
    "str( get_rect(i, j, i + h/3 -1, j+w-1 )/(2/3) - get_rect(i+h/3, j, i + 2*h//3-1, j+ w -1 )/(1/3) - get_rect(i+2 * h//3, j, i + h-1, j+w-1 )/ (2/3))\n",
    "\n",
    "                                                                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
