{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from dask import delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Integral Image\n",
    "\n",
    "Computes rectangle integrals of an image for fast computation of Harr Filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intg_image(img):\n",
    "    \"\"\"\n",
    "    Computes matrix for quick computation of integrals.\n",
    "    \"\"\"\n",
    "    # Create a matrix of zeros with the same dimensions as the input image\n",
    "    intg_img = np.zeros(img.shape, dtype=np.int64)\n",
    "    \n",
    "    # Iterate over each pixel in the input image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the sum of all pixels above and to the left of the current pixel\n",
    "            if i > 0:\n",
    "                intg_img[i, j] += intg_img[i-1, j]\n",
    "            if j > 0:\n",
    "                intg_img[i, j] += intg_img[i, j-1]\n",
    "            if i > 0 and j > 0:\n",
    "                intg_img[i, j] -= intg_img[i-1, j-1]\n",
    "            \n",
    "            # Add the value of the current pixel to the integral image\n",
    "            intg_img[i, j] += img[i, j]\n",
    "    \n",
    "    # Return the computed integral image\n",
    "    return intg_img\n",
    "\n",
    "def get_rect(intg_img, si, sj, ei, ej):\n",
    "    # Calculate the sum of all pixels within the specified rectangular region\n",
    "    result = intg_img[ei, ej]\n",
    "    if si > 0:\n",
    "        result -= intg_img[si-1, ej]\n",
    "    if sj > 0:\n",
    "        result -= intg_img[ei, sj-1]\n",
    "    if si > 0 and sj > 0:\n",
    "        result += intg_img[si-1, sj-1]\n",
    "    \n",
    "    # Return the computed sum of pixels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ones((3,3))\n",
    "intg_img = compute_intg_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rect(intg_img, 0,0, 2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_imgs = []\n",
    "for file in os.listdir('data/'):\n",
    "    if \".pgm\" in file:\n",
    "        face_imgs.append(cv2.imread(\"data/\"+file,-1))\n",
    "cv2.imshow(\"face\", np.hstack(face_imgs))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    imgs = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".pgm\" in file:\n",
    "            imgs.append(cv2.imread(folder+\"/\"+file,-1))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 128)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import haar_like_feature, draw_haar_like_feature, haar_like_feature_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_like_feature(compute_intg_image(face_imgs[0]),0,0,face_imgs[0].shape[1], face_imgs[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "draw_haar_like_feature() missing 1 required positional argument: 'feature_coord'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m draw_haar_like_feature(intg_img,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m19\u001b[39;49m, \u001b[39m19\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: draw_haar_like_feature() missing 1 required positional argument: 'feature_coord'"
     ]
    }
   ],
   "source": [
    "draw_haar_like_feature(intg_img,0,0,19, 19, haar_like_feature_coord())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "intg_img = compute_intg_image(face_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intg_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = face_imgs[0]\n",
    "kernel_size = 40\n",
    "for i in range(0, img.shape[0], 10):\n",
    "    for j in range(0, img.shape[1], 10):\n",
    "        if i+kernel_size <= img.shape[0] and j+kernel_size <= img.shape[1]:\n",
    "            cv2.imshow(\"img\",cv2.rectangle(img.copy(), (j, i), (j+kernel_size-1, i+kernel_size-1), 255, 2 ))\n",
    "            cv2.imshow(\"roi\", cv2.resize(img[i:i+kernel_size, j:j+kernel_size], (100,100)))\n",
    "            cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haar_features(intg_img, haar_filters, feature_size):\n",
    "    haar_features = np.zeros(feature_size)\n",
    "    idx = 0\n",
    "    for filter in haar_filters:\n",
    "        for i in range(intg_img.shape[0]-filter[0]+1):\n",
    "            for j in range(intg_img.shape[1]-filter[1]+1):\n",
    "             \n",
    "                if filter[2]:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]-1, j+filter[1]//2-1) \n",
    "                    - get_rect(intg_img, i, j+filter[1]//2, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])\n",
    "                else:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]//2-1, j +filter[1]-1) \n",
    "                    - get_rect(intg_img, i+filter[0]//2, j, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])\n",
    "                haar_features[idx] = result\n",
    "                idx += 1\n",
    "            \n",
    "        \n",
    "    return haar_features\n",
    "def generate_haar_filters(detector_size=19):\n",
    "    haar_feature_size = 0\n",
    "    # (r, c, is_vert)\n",
    "    haar_filters= []\n",
    "    for i in range(1, detector_size+1):\n",
    "        for j in range(1, detector_size+1):\n",
    "            if i % 2 == 0:\n",
    "                haar_filters.append((i,j, 0))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "            if j % 2 == 0:\n",
    "                haar_filters.append((i,j, 1))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "    return haar_feature_size, haar_filters\n",
    "\n",
    "def get_haar_feature_extractor(detector_size):\n",
    "    haar_feature_size, haar_filters = generate_haar_filters(detector_size)\n",
    "    @delayed\n",
    "    def get_haar(intg_img):\n",
    "        return compute_haar_features(intg_img, haar_filters, haar_feature_size)\n",
    "    return get_haar\n",
    "\n",
    "haar_feature_extractor = get_haar_feature_extractor(19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.5       ,  -8.5       , -11.        , ...,   0.96381579,\n",
       "        -5.00292398,  -0.47076023])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34200,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_haar_features(intg_img, haar_filters).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4548"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask\n",
      "  Downloading dask-2023.4.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click>=7.0 (from dask)\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle>=1.1.1 (from dask)\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec>=0.6.0 (from dask)\n",
      "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from dask) (23.1)\n",
      "Collecting partd>=1.2.0 (from dask)\n",
      "  Downloading partd-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting pyyaml>=5.3.1 (from dask)\n",
      "  Downloading PyYAML-6.0-cp310-cp310-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting toolz>=0.8.2 (from dask)\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib-metadata>=4.13.0 (from dask)\n",
      "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.13.0->dask)\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting locket (from partd>=1.2.0->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: zipp, toolz, pyyaml, locket, fsspec, cloudpickle, click, partd, importlib-metadata, dask\n",
      "Successfully installed click-8.1.3 cloudpickle-2.2.1 dask-2023.4.0 fsspec-2023.4.0 importlib-metadata-6.6.0 locket-1.0.0 partd-1.4.0 pyyaml-6.0 toolz-0.12.0 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_true = load_folder(\"train/face\")[:200]\n",
    "train_x_false = load_folder(\"train/non-face\")[:200]\n",
    "train_y_true = [1] * len(train_x_true)\n",
    "train_y_false = [0] * len(train_x_false)\n",
    "\n",
    "train_x = train_x_true + train_x_false\n",
    "train_y = train_y_true + train_y_false\n",
    "\n",
    "train_x = delayed(haar_feature_extractor(compute_intg_image(img)) for img in train_x)\n",
    "\n",
    "train_x = np.array(train_x.compute(scheduler='single-threaded')))\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 8])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(2,[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn' has no attribute 'linear_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sklearn\u001b[39m.\u001b[39;49mlinear_model\u001b[39m.\u001b[39mPerceptron()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn' has no attribute 'linear_model'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adaboost(train_x, train_y, haar_feature_extractor, T=100):\n",
    "    face_count = 0\n",
    "    non_face_count = 0\n",
    "    \n",
    "    for i, label in enumerate(train_y):\n",
    "        if label:\n",
    "            face_count += 1\n",
    "        else:\n",
    "            non_face_count += 1\n",
    "\n",
    "    w = np.array([1/face_count if train_y[i] else 1/non_face_count for i in range(len(train_y))])\n",
    "\n",
    "    classifiers = []\n",
    "    beta = np.zeros(T)\n",
    "    for t in range(T):\n",
    "        w = w / np.sum(w)\n",
    "\n",
    "        model = Perceptron()\n",
    "        model.fit(train_x, train_y, w)\n",
    "        e = np.abs(train_y - model.predict(train_x))\n",
    "        \n",
    "        beta[t] = np.sum(w * e)\n",
    "        w = w * np.power(beta[t], 1-e)\n",
    "        classifiers.append(model)\n",
    "    alpha = np.log(1/beta)\n",
    "    predictions = np.sum(np.array([c.predict(train_x) for c in classifiers]) * alpha, axis=0)[:face_count]\n",
    "    threshold = np.min(predictions)\n",
    "    print(threshold)\n",
    "    \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.64181756943333\n"
     ]
    }
   ],
   "source": [
    "face_count = 0\n",
    "non_face_count = 0\n",
    "T = 400\n",
    "for i, label in enumerate(train_y):\n",
    "    if label:\n",
    "        face_count += 1\n",
    "    else:\n",
    "        non_face_count += 1\n",
    "w = np.array([1/face_count if train_y[i] else 1/non_face_count for i in range(len(train_y))])\n",
    "\n",
    "classifiers = []\n",
    "beta = np.zeros(T)\n",
    "for t in range(T):\n",
    "    w = w / np.sum(w)\n",
    "\n",
    "    model = Perceptron()\n",
    "    model.fit(train_x, train_y, sample_weight=w)\n",
    "    e = np.abs(train_y - model.predict(train_x))\n",
    "    \n",
    "    beta[t] = np.sum(w * e)\n",
    "    w = w * np.power(beta[t], 1-e)\n",
    "    classifiers.append(model)\n",
    "alpha = np.log(1/beta)\n",
    "predictions = np.sum( np.array([c.predict(train_x) for c in classifiers]) * alpha.reshape(-1,1), axis=0)[:face_count]\n",
    "threshold = np.min(predictions)\n",
    "print(threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    predictions = np.sum( np.array([c.predict(data) for c in classifiers]) * alpha.reshape(-1,1), axis=0)\n",
    "    return predictions >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_true = load_folder(\"train/face\")[200:220]\n",
    "test_x_false = load_folder(\"train/non-face\")[200:220]\n",
    "test_y_true = [1] * len(test_x_true)\n",
    "test_y_false = [0] * len(test_x_false)\n",
    "\n",
    "test_x = test_x_true + test_x_false\n",
    "test_y = test_y_true + test_y_false\n",
    "\n",
    "test_x = delayed(haar_feature_extractor(compute_intg_image(img)) for img in test_x)\n",
    "test_x = np.array(test_x.compute(scheduler='single-threaded'))\n",
    "test_y = np.array(test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True, False, False,  True, False, False, False,  True,\n",
       "       False, False,  True, False,  True, False,  True, False,  True,\n",
       "        True, False, False, False])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
