{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from dask import delayed\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Integral Image\n",
    "\n",
    "Computes rectangle integrals of an image for fast computation of Harr Filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intg_image(img):\n",
    "    \"\"\"\n",
    "    Computes matrix for quick computation of integrals.\n",
    "    \"\"\"\n",
    "    # Create a matrix of zeros with the same dimensions as the input image\n",
    "    intg_img = np.zeros(img.shape, dtype=np.int64)\n",
    "    \n",
    "    # Iterate over each pixel in the input image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the sum of all pixels above and to the left of the current pixel\n",
    "            if i > 0:\n",
    "                intg_img[i, j] += intg_img[i-1, j]\n",
    "            if j > 0:\n",
    "                intg_img[i, j] += intg_img[i, j-1]\n",
    "            if i > 0 and j > 0:\n",
    "                intg_img[i, j] -= intg_img[i-1, j-1]\n",
    "            \n",
    "            # Add the value of the current pixel to the integral image\n",
    "            intg_img[i, j] += img[i, j]\n",
    "    \n",
    "    # Return the computed integral image\n",
    "    return intg_img\n",
    "\n",
    "def get_rect(intg_img, si, sj, ei, ej):\n",
    "    # Calculate the sum of all pixels within the specified rectangular region\n",
    "    result = intg_img[ei, ej]\n",
    "    if si > 0:\n",
    "        result -= intg_img[si-1, ej]\n",
    "    if sj > 0:\n",
    "        result -= intg_img[ei, sj-1]\n",
    "    if si > 0 and sj > 0:\n",
    "        result += intg_img[si-1, sj-1]\n",
    "    \n",
    "    # Return the computed sum of pixels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    imgs = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".pgm\" in file:\n",
    "            imgs.append(cv2.imread(folder+\"/\"+file,-1))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haar_features(intg_img, haar_filters, feature_size):\n",
    "    haar_features = []\n",
    "    \n",
    "    for filter in haar_filters:\n",
    "        filter_feature = []\n",
    "        for i in range(intg_img.shape[0]-filter[0]+1):\n",
    "            for j in range(intg_img.shape[1]-filter[1]+1):\n",
    "             \n",
    "                if filter[2]:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]-1, j+filter[1]//2-1) \n",
    "                    - get_rect(intg_img, i, j+filter[1]//2, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])\n",
    "                else:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]//2-1, j +filter[1]-1) \n",
    "                    - get_rect(intg_img, i+filter[0]//2, j, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])\n",
    "                filter_feature.append(result)\n",
    "        haar_features.append(filter_feature)\n",
    "\n",
    "    return haar_features\n",
    "def generate_haar_filters(detector_size=19):\n",
    "    haar_feature_size = 0\n",
    "    # (r, c, is_vert)\n",
    "    haar_filters= []\n",
    "    for i in range(1, detector_size+1):\n",
    "        for j in range(1, detector_size+1):\n",
    "            if i % 2 == 0:\n",
    "                haar_filters.append((i,j, 0))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "            if j % 2 == 0:\n",
    "                haar_filters.append((i,j, 1))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "    return haar_feature_size, haar_filters\n",
    "\n",
    "def get_haar_feature_extractor(detector_size):\n",
    "    haar_feature_size, haar_filters = generate_haar_filters(detector_size)\n",
    "    @delayed\n",
    "    def get_haar(intg_img):\n",
    "        return compute_haar_features(intg_img, haar_filters, haar_feature_size)\n",
    "    return get_haar\n",
    "\n",
    "haar_feature_extractor = get_haar_feature_extractor(19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_true = load_folder(\"train/face\")[:200]\n",
    "train_x_false = load_folder(\"train/non-face\")[:200]\n",
    "train_y_true = [1] * len(train_x_true)\n",
    "train_y_false = [0] * len(train_x_false)\n",
    "\n",
    "train_x = train_x_true + train_x_false\n",
    "train_y = train_y_true + train_y_false\n",
    "\n",
    "train_x = delayed(haar_feature_extractor(compute_intg_image(img)) for img in train_x)\n",
    "\n",
    "train_x = train_x.compute(scheduler='single-threaded')\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adaboost(train_x, train_y, d=1, T=100):\n",
    "    face_count = 0\n",
    "    non_face_count = 0\n",
    "    for i, label in enumerate(train_y):\n",
    "        if label:\n",
    "            face_count += 1\n",
    "        else:\n",
    "            non_face_count += 1\n",
    "    w = np.array([1/face_count if train_y[i] else 1/non_face_count for i in range(len(train_y))])\n",
    "\n",
    "    classifiers = []\n",
    "    feature_sel = []\n",
    "    beta = np.zeros(T)\n",
    "\n",
    "    def select_features(x_data, x_sel):\n",
    "        return [np.hstack([x[f] for f in x_sel]) for x in x_data]\n",
    "\n",
    "    for t in range(T):\n",
    "        w = w / np.sum(w)\n",
    "        while True: \n",
    "            model = Perceptron()\n",
    "            m_sel = np.random.permutation(len(train_x[0]))[:d]\n",
    "            m_train_x = select_features(train_x, m_sel)\n",
    "            model.fit(m_train_x, train_y, sample_weight=w)\n",
    "            e = np.abs(train_y - model.predict(m_train_x))\n",
    "            \n",
    "            beta[t] = np.sum(w * e)\n",
    "            if beta[t] < 0.5:\n",
    "                \n",
    "                feature_sel.append(m_sel)\n",
    "                w = w * np.power(beta[t], 1-e)\n",
    "                classifiers.append(model)\n",
    "                break\n",
    "            \n",
    "        \n",
    "    alpha = np.log(1/beta)\n",
    "    predictions = np.sum( np.array([c.predict(select_features(train_x, f_sel)) for c, f_sel in zip(classifiers, feature_sel) ]) * alpha.reshape(-1,1), axis=0)[train_y==1]\n",
    "    threshold = np.min(predictions)\n",
    "    def model(x):\n",
    "        predictions = np.sum( np.array([c.predict(select_features(x, f_sel)) for c, f_sel in zip(classifiers, feature_sel)]) * alpha.reshape(-1,1), axis=0)\n",
    "        return predictions >= threshold\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    predictions = np.sum( np.array([c.predict(data) for c in classifiers]) * alpha.reshape(-1,1), axis=0)\n",
    "    return predictions >= threshold\n",
    "\n",
    "\n",
    "model = Adaboost(x, y)\n",
    "y_pred = model(x)\n",
    "def train_classifier(n=20,x,y):\n",
    "    for j in range(n):\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_true = load_folder(\"train/face\")[200:220]\n",
    "test_x_false = load_folder(\"train/non-face\")[200:220]\n",
    "test_y_true = [1] * len(test_x_true)\n",
    "test_y_false = [0] * len(test_x_false)\n",
    "\n",
    "test_x = test_x_true + test_x_false\n",
    "test_y = test_y_true + test_y_false\n",
    "\n",
    "test_x = delayed(haar_feature_extractor(compute_intg_image(img)) for img in test_x)\n",
    "test_x = np.array(test_x.compute(scheduler='single-threaded'))\n",
    "test_y = np.array(test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True, False, False,  True, False, False, False,  True,\n",
       "       False, False,  True, False,  True, False,  True, False,  True,\n",
       "        True, False, False, False])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39ma\u001b[39m(x,y):\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m X_new \u001b[39m=\u001b[39m SelectPercentile(a, percentile\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(X, y)\n\u001b[1;32m      8\u001b[0m X_new\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/base.py:881\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/feature_selection/_base.py:90\u001b[0m, in \u001b[0;36mSelectorMixin.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39m# note: we use _safe_tags instead of _get_tags because this is a\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m# public Mixin.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m     84\u001b[0m     X,\n\u001b[1;32m     85\u001b[0m     dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     89\u001b[0m )\n\u001b[0;32m---> 90\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X)\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/feature_selection/_base.py:94\u001b[0m, in \u001b[0;36mSelectorMixin._transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     93\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Reduce X to the selected features.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_support()\n\u001b[1;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m     96\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     97\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNo features were selected: either the data is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m too noisy or the selection test too strict.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m             \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m    100\u001b[0m         )\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/feature_selection/_base.py:53\u001b[0m, in \u001b[0;36mSelectorMixin.get_support\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_support\u001b[39m(\u001b[39mself\u001b[39m, indices\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m    Get a mask, or integer index, of the features selected.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m        values are indices into the input feature vector.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_support_mask()\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m mask \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indices \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39mwhere(mask)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/ee769/Project/.venv/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:585\u001b[0m, in \u001b[0;36mSelectPercentile._get_support_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m ties \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(scores \u001b[39m==\u001b[39m threshold)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ties):\n\u001b[0;32m--> 585\u001b[0m     max_feats \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39;49m(scores) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpercentile \u001b[39m/\u001b[39m \u001b[39m100\u001b[39m)\n\u001b[1;32m    586\u001b[0m     kept_ties \u001b[39m=\u001b[39m ties[: max_feats \u001b[39m-\u001b[39m mask\u001b[39m.\u001b[39msum()]\n\u001b[1;32m    587\u001b[0m     mask[kept_ties] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
