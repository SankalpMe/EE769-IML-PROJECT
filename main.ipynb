{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Integral Image\n",
    "\n",
    "Computes rectangle integrals of an image for fast computation of Harr Filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intg_image(img):\n",
    "    \"\"\"\n",
    "    Computes matrix for quick computation of integrals.\n",
    "    \"\"\"\n",
    "    # Create a matrix of zeros with the same dimensions as the input image\n",
    "    intg_img = np.zeros(img.shape, dtype=np.int64)\n",
    "    \n",
    "    # Iterate over each pixel in the input image\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            # Calculate the sum of all pixels above and to the left of the current pixel\n",
    "            if i > 0:\n",
    "                intg_img[i, j] += intg_img[i-1, j]\n",
    "            if j > 0:\n",
    "                intg_img[i, j] += intg_img[i, j-1]\n",
    "            if i > 0 and j > 0:\n",
    "                intg_img[i, j] -= intg_img[i-1, j-1]\n",
    "            \n",
    "            # Add the value of the current pixel to the integral image\n",
    "            intg_img[i, j] += img[i, j]\n",
    "    \n",
    "    # Return the computed integral image\n",
    "    return intg_img\n",
    "\n",
    "def get_rect(intg_img, si, sj, ei, ej):\n",
    "    # Calculate the sum of all pixels within the specified rectangular region\n",
    "    result = intg_img[ei, ej]\n",
    "    if si > 0:\n",
    "        result -= intg_img[si-1, ej]\n",
    "    if sj > 0:\n",
    "        result -= intg_img[ei, sj-1]\n",
    "    if si > 0 and sj > 0:\n",
    "        result += intg_img[si-1, sj-1]\n",
    "    \n",
    "    # Return the computed sum of pixels\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m\n\u001b[1;32m     22\u001b[0m                 result_img[i\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39mfilter\u001b[39m[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m],  j\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39mfilter\u001b[39m[\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m result\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m result_img\n\u001b[0;32m---> 28\u001b[0m fal_1 \u001b[39m=\u001b[39m run_filter(c_img, intg_img, harr_filter_4)\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(fal_1\u001b[39m.\u001b[39mmax())\n\u001b[1;32m     30\u001b[0m fal_1 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mthreshold(fal_1, \u001b[39m10\u001b[39m, \u001b[39m255\u001b[39m,cv2\u001b[39m.\u001b[39mTHRESH_BINARY)[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c_img' is not defined"
     ]
    }
   ],
   "source": [
    "# (height, width), stride (y, x) [rect: pos start (i,j), rect pos end (i,j), wt]\n",
    "harr_filter_1 = [(20,40), (5, 5) ,[(0, 0, 9, 39, -1) , (10,0,19,39, 1)]]\n",
    "harr_filter_2 = [(40,10), (5, 5) ,[(0, 0, 39, 4, 1) , (0,5,39,9, -1)]]\n",
    "\n",
    "harr_filter_3 = [(24,40), (5, 5) ,[(0, 0, 7, 39, -0.5), (8, 0, 15, 39, 1), (16, 0, 23, 39, -0.5)]]\n",
    "\n",
    "harr_filter_4 = [(40,24), (5, 5) ,[(0, 0, 39, 7, -0.5), (0, 8, 39, 15, 1), (0, 16, 39, 23, -0.5)]]\n",
    "\n",
    "\n",
    "\n",
    "def run_filter(c_img , intg_img, filter):\n",
    "    result_img = np.zeros((intg_img.shape[0]//filter[1][0], intg_img.shape[1]//filter[1][1])) \n",
    "    \n",
    "    for i in range(0, intg_img.shape[0]-filter[0][0]+1, filter[1][0]):\n",
    "        for j in range(0, intg_img.shape[1]-filter[0][1]+1, filter[1][1]):\n",
    "            # r_img = c_img.copy()\n",
    "            if (i+filter[0][0]) < intg_img.shape[0] and (j + filter[0][1]) < intg_img.shape[1]:\n",
    "                result = 0\n",
    "                for rect_filter in filter[2]:\n",
    "                    # cv2.rectangle(r_img, (j+rect_filter[1],i+rect_filter[0]), (j+rect_filter[3],i+rect_filter[2]), (255,0,0), 1)\n",
    "                    result += (rect_filter[4] * get_rect(intg_img, i+rect_filter[0], j+rect_filter[1], i+rect_filter[2], j+rect_filter[3]) ) / ((rect_filter[2]-rect_filter[0]+1)*(rect_filter[3]-rect_filter[1]+1))\n",
    "                result_img[i//filter[1][0],  j//filter[1][1]] = result\n",
    "            \n",
    "       \n",
    "            \n",
    "     \n",
    "    return result_img\n",
    "fal_1 = run_filter(c_img, intg_img, harr_filter_4)\n",
    "print(fal_1.max())\n",
    "fal_1 = cv2.threshold(fal_1, 10, 255,cv2.THRESH_BINARY)[1]\n",
    "\n",
    "\n",
    "cv2.imshow(\"set\", fal_1)\n",
    "cv2.imshow(\"orig\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_haar_filter(height, width, white_subrects, black_subrects, stride=(5,5)):\n",
    "    # Initialize:\n",
    "    # 1. An empty list to store the sub-rectangles\n",
    "    rects = []\n",
    "    # 2. A variable to count the number of white sub-rectangles\n",
    "    white_count = 0\n",
    "    # 3. A variable to count the number of black sub-rectangles                 \n",
    "    black_count = 0\n",
    "    \n",
    "    # Loop over the white sub-rectangles and compute the total number of white pixels\n",
    "    for subrect in white_subrects:\n",
    "        white_count += (subrect[2]-subrect[0]+1)*(subrect[3]-subrect[1]+1)\n",
    "    \n",
    "    # Loop over the black sub-rectangles and compute the total number of black pixels\n",
    "    for subrect in black_subrects:\n",
    "        black_count += (subrect[2]-subrect[0]+1)*(subrect[3]-subrect[1]+1)\n",
    "    \n",
    "    # Loop over the white sub-rectangles and append their coordinates and weights to the list of sub-rectangles\n",
    "    for subrect in white_subrects:\n",
    "        rects.append([subrect[0], subrect[1], subrect[2], subrect[3], -1/white_count])\n",
    "    \n",
    "    # Loop over the black sub-rectangles and append their coordinates and weights to the list of sub-rectangles\n",
    "    for subrect in black_subrects:\n",
    "        rects.append([subrect[0], subrect[1], subrect[2], subrect[3], 1/black_count])\n",
    "    \n",
    "    # Return a list of the filter kernel dimensions, stride, and sub-rectangles with their weights\n",
    "    return [(height, width), stride, rects]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haar_features(intg_img, haar_filter):\n",
    "    # Get the shape of the integral image and the Haar filter\n",
    "    img_shape = intg_img.shape\n",
    "    filter_shape = haar_filter[0]\n",
    "\n",
    "    # Get the stride of the Haar filter\n",
    "    stride = haar_filter[1]\n",
    "\n",
    "    # Create an empty result image with the appropriate shape\n",
    "    res_img = np.zeros((img_shape[0]//stride[0], img_shape[1]//stride[1]))\n",
    "\n",
    "    # Iterate over the image with the Haar filter\n",
    "    for i in range(0, img_shape[0]-filter_shape[0]+1, stride[0]):\n",
    "        for j in range(0, img_shape[1]-filter_shape[1]+1, stride[1]):\n",
    "            # If the Haar filter fits inside the image at this position\n",
    "            if (i+filter_shape[0]) < img_shape[0] and (j + filter_shape[1]) < img_shape[1]:\n",
    "                result = 0\n",
    "                # Compute the Haar feature by summing over the rectangles in the Haar filter\n",
    "                for rect in haar_filter[2]:\n",
    "                    result += rect[4] * get_rect(intg_img, i+rect[0], j+rect[1], i+rect[2], j+rect[3])\n",
    "                # Set the result of the Haar feature in the appropriate position in the result image\n",
    "                res_img[i//stride[0],  j//stride[1]] = result\n",
    "\n",
    "    # Return the result image\n",
    "    return res_img\n",
    "\n",
    "def render_filter(haar_filter):\n",
    "    # Create an empty image with the shape of the Haar filter\n",
    "    img = np.zeros(haar_filter[0])\n",
    "\n",
    "    # Iterate over the rectangles in the Haar filter\n",
    "    for rect in haar_filter[2]:\n",
    "        # If the rectangle has a negative weight, mark it as white in the image\n",
    "        if(rect[4] < 0):\n",
    "            img[rect[0]:rect[2]+1, rect[1]:rect[3]+1] = 1\n",
    "\n",
    "    # Display the image with a grayscale colormap\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "harr_filter_1 = [(20,40), (5, 5) ,[(0, 0, 9, 39, -1) , (10,0,19,39, 1)]]\n",
    "harr_filter_2 = [(40,10), (5, 5) ,[(0, 0, 39, 4, 1) , (0,5,39,9, -1)]]\n",
    "\n",
    "harr_filter_3 = [(24,40), (5, 5) ,[(0, 0, 7, 39, -0.5), (8, 0, 15, 39, 1), (16, 0, 23, 39, -0.5)]]\n",
    "\n",
    "harr_filter_4 = [(40,24), (5, 5) ,[(0, 0, 39, 7, -0.5), (0, 8, 39, 15, 1), (0, 16, 39, 23, -0.5)]]\n",
    "\n",
    "# class 1\n",
    "def haar_c1_h_filter(height, width):\n",
    "    return create_haar_filter(height, width, [ (0,0, height//2-1, width-1) ], [ (height//2, 0, height-1, width-1) ])\n",
    "def haar_c1_v_filter(height, width):\n",
    "    return create_haar_filter(height, width, [ (0,0, height-1, width//2-1) ], [ (0, width//2, height-1, width-1) ])\n",
    "\n",
    "# class 2\n",
    "def haar_c2_h_filter(height, width):\n",
    "    return create_haar_filter(height, width, [ (0, 0, height//3-1, width-1),  (2*height//3, 0, height-1, width-1)  ], [ (height//3, 0, 2*height//3-1, width-1) ])\n",
    "def haar_c2_v_filter(height, width):\n",
    "    return create_haar_filter(height, width, [ (0, 0, height-1, width//3-1),  (0, 2*width//3, height-1, width-1)  ], [ (0, width//3, height-1, 2*width//3-1) ])\n",
    "def haar_c2_s_filter(height, width):\n",
    "    return create_haar_filter(height, width, [ (0,0, width//2-1, height//2-1), (height//2, width//2, height-1, width-1)], [(0, width//2, height//2-1, width-1), (height//2, 0, width//2-1, height-1)])\n",
    "\n",
    "# class 3\n",
    "\n",
    "def haar_c3_s_filter(height, width, factor):\n",
    "    return create_haar_filter(height, width, [ (0,0, (width-width*factor)//2, height//2-1), (height//2, width//2, height-1, width-1)], [(0, width//2, height//2-1, width-1), (height//2, 0, width//2-1, height-1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m ret, frame \u001b[39m=\u001b[39m vid\u001b[39m.\u001b[39mread()\n\u001b[1;32m     15\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY), (\u001b[39m200\u001b[39m,\u001b[39m200\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m intg_img \u001b[39m=\u001b[39m compute_intg_image(img)\n\u001b[1;32m     17\u001b[0m draw_grid(img)\n\u001b[1;32m     18\u001b[0m \u001b[39m#filt_imgs = [cv2.threshold(compute_haar_features(intg_img, filt), thresh, 255, cv2.THRESH_BINARY)[1] for thresh, filt in zip(thresholds, haar_filters) ]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m, in \u001b[0;36mcompute_intg_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     17\u001b[0m             intg_img[i, j] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m intg_img[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, j\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m         \u001b[39m# Add the value of the current pixel to the integral image\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m         intg_img[i, j] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m img[i, j]\n\u001b[1;32m     22\u001b[0m \u001b[39m# Return the computed integral image\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m intg_img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "  \n",
    "  \n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "haar_filters = [haar_c1_h_filter(20,50), haar_c1_v_filter(60,30), haar_c2_h_filter(21,40), haar_c2_v_filter(60,30), haar_c2_s_filter(30,30)]\n",
    "thresholds = [20,40,10,10]\n",
    "colours = [np.random.random(3) for i in range(4)]\n",
    "k_rows = 1\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "    img = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), (200,200))\n",
    "    intg_img = compute_intg_image(img)\n",
    "    draw_grid(img)\n",
    "    #filt_imgs = [cv2.threshold(compute_haar_features(intg_img, filt), thresh, 255, cv2.THRESH_BINARY)[1] for thresh, filt in zip(thresholds, haar_filters) ]\n",
    "    filt_imgs = [compute_haar_features(intg_img, filt) for \n",
    "                 filt in  haar_filters ]\n",
    "    \n",
    "    filt_imgs = [ cv2.threshold(img, 0, 0, cv2.THRESH_TOZERO)[1] / np.max(img) for img in filt_imgs]\n",
    "    filt_img = np.vstack([np.hstack([filt_imgs[i+j*k_rows] for i in range(k_rows)]) for j in range(len(haar_filters)//k_rows)])\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', img)\n",
    "    cv2.imshow(\"HARR FILTERS\",cv2.resize(filt_img, (200*k_rows, 200*len(haar_filters)//k_rows)))\n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    cv2.waitKey(2)\n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "positive =0\n",
    "negative =0\n",
    "wt=np.zeros(img_list.shape)\n",
    "for i in range(img_list.shape):\n",
    "    if img_list[i]==1:\n",
    "        positive +=1\n",
    "    else:\n",
    "        negative +=1\n",
    "for i in range(img_list.shape):\n",
    "    if img_list[i]==1:\n",
    "        wt[i]=1/(2*positive)\n",
    "    else:\n",
    "        wt[i]=1/(2*negative)\n",
    "\n",
    "\n",
    "\n",
    "model=sklearn.linear_model.Perceptron(penalty='l2',alpha=0.01)\n",
    "max_iter=1000\n",
    "\n",
    "arg_min=np.zeros(max_iter,'uint16')\n",
    "beta=np.zeros(max_iter,'float')\n",
    "e=np.zeros(haar.shape[0])\n",
    "pred=np.zeros((haar.shape[0],haar.shape[2]),'float')\n",
    "\n",
    "model_list=[0]*haar.shape[0]\n",
    "best_list=[0]*max_iter\n",
    "\n",
    "for iter in range(max_iter):\n",
    "    norm_wt=wt.copy()\n",
    "    for i in range(img_list.shape):\n",
    "        norm_wt[i]=wt[i]/np.sum(wt)\n",
    "    wt=norm_wt\n",
    "    for j in range(haar.shape[0]):\n",
    "        # for i in range(img_num):\n",
    "        model.fit_(harr[j,:,:],img_list)\n",
    "        pred[j,:]=model.predict(harr[j,:,:])\n",
    "\n",
    "        model_list[j]=model.copy()\n",
    "\n",
    "        e[j]=np.dot(wt,np.abs(np.dot(pred[j,:],img_list)))\n",
    "\n",
    "    arg_min[iter]=np.argmin(e)\n",
    "    best_list[iter]=model_list[arg_min[iter]].copy()\n",
    "    beta[iter]=e[arg_min]/(1-e[arg_min])\n",
    "\n",
    "    new_wt=wt.copy()\n",
    "    for i in range(haar.shape[2]):\n",
    "        if(np.round(pred[arg_min[iter],i],2)==img_list):\n",
    "            new_wt[i]=wt[i]*(beta[iter])\n",
    "    wt=new_wt\n",
    "\n",
    "\n",
    "def fun( features ):\n",
    "    sum_wt=0\n",
    "    sum_out=0\n",
    "    for iter in range(max_iter):\n",
    "        model=best_list[max_iter].copy()\n",
    "        sum_out+=np.log(beta[iter])*(-model.predict(features))\n",
    "        sum_wt+=(-0.5)*np.log(beta[iter])\n",
    "    if(sum_out>=sum_wt):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ones((3,3))\n",
    "intg_img = compute_intg_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rect(intg_img, 0,0, 2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_imgs = []\n",
    "for file in os.listdir('data/'):\n",
    "    if \".pgm\" in file:\n",
    "        face_imgs.append(cv2.imread(\"data/\"+file,-1))\n",
    "cv2.imshow(\"face\", np.hstack(face_imgs))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(folder):\n",
    "    imgs = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".pgm\" in file:\n",
    "            imgs.append(cv2.imread(folder+\"/\"+file,-1))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 128)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import haar_like_feature, draw_haar_like_feature, haar_like_feature_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_like_feature(compute_intg_image(face_imgs[0]),0,0,face_imgs[0].shape[1], face_imgs[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "draw_haar_like_feature() missing 1 required positional argument: 'feature_coord'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m draw_haar_like_feature(intg_img,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m19\u001b[39;49m, \u001b[39m19\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: draw_haar_like_feature() missing 1 required positional argument: 'feature_coord'"
     ]
    }
   ],
   "source": [
    "draw_haar_like_feature(intg_img,0,0,19, 19, haar_like_feature_coord())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "intg_img = compute_intg_image(face_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intg_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = face_imgs[0]\n",
    "kernel_size = 40\n",
    "for i in range(0, img.shape[0], 10):\n",
    "    for j in range(0, img.shape[1], 10):\n",
    "        if i+kernel_size <= img.shape[0] and j+kernel_size <= img.shape[1]:\n",
    "            cv2.imshow(\"img\",cv2.rectangle(img.copy(), (j, i), (j+kernel_size-1, i+kernel_size-1), 255, 2 ))\n",
    "            cv2.imshow(\"roi\", cv2.resize(img[i:i+kernel_size, j:j+kernel_size], (100,100)))\n",
    "            cv2.waitKey(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_haar_features(intg_img, haar_filters, feature_size):\n",
    "    haar_features = np.zeros(feature_size)\n",
    "    idx = 0\n",
    "    for filter in haar_filters:\n",
    "        for i in range(intg_img.shape[0]-filter[0]+1):\n",
    "            for j in range(intg_img.shape[1]-filter[1]+1):\n",
    "             \n",
    "                if filter[2]:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]-1, j+filter[1]//2-1) \n",
    "                    - get_rect(intg_img, i, j+filter[1]//2, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])\n",
    "                else:\n",
    "                    result = ( get_rect(intg_img, i, j, i+filter[0]//2-1, j +filter[1]-1) \n",
    "                    - get_rect(intg_img, i+filter[0]//2, j, i+filter[0]-1, j+filter[1]-1) )/((filter[0])*filter[1])\n",
    "                haar_features[idx] = result\n",
    "                idx += 1\n",
    "            \n",
    "        \n",
    "    return haar_features\n",
    "def generate_haar_filters(detector_size=19):\n",
    "    haar_feature_size = 0\n",
    "    # (r, c, is_vert)\n",
    "    haar_filters= []\n",
    "    for i in range(1, detector_size+1):\n",
    "        for j in range(1, detector_size+1):\n",
    "            if i % 2 == 0:\n",
    "                haar_filters.append((i,j, 0))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "            if j % 2 == 0:\n",
    "                haar_filters.append((i,j, 1))\n",
    "                haar_feature_size += (19-i+1) * (19-j+1)\n",
    "    return haar_feature_size, haar_filters\n",
    "\n",
    "def get_haar_feature_extractor(detector_size):\n",
    "    haar_feature_size, haar_filters = generate_haar_filters(detector_size)\n",
    "    def get_haar(intg_img):\n",
    "        return compute_haar_features(intg_img, haar_filters, haar_feature_size)\n",
    "    return get_haar\n",
    "\n",
    "haar_feature_extractor = get_haar_feature_extractor(19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.5       ,  -8.5       , -11.        , ...,   0.96381579,\n",
       "        -5.00292398,  -0.47076023])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34200,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_haar_features(intg_img, haar_filters).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_true = load_folder(\"train/face\")\n",
    "train_x_false = load_folder(\"train/non-face\")\n",
    "train_y_true = [1] * len(train_x_true)\n",
    "train_y_false = [0] * len(train_x_false)\n",
    "\n",
    "train_x = train_x_true + train_x_false\n",
    "train_y = train_y_true + train_y_false\n",
    "\n",
    "train_x = [compute_intg_image(img) for img in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6977"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238613400"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6977 * 34200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
